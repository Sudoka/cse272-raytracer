\section*{Task 2}
Our second task was to render a scene using Adaptive Progressive Photon mapping. We rendered a 512x512 image where each pixel is represented by a measurement point. We utilized our ray tracer from the previous course CSE 168 to handle the scene rendering. The initial pass traces a ray sent from each image pixel into the scene. The measurement point is stored at the first hit diffuse surface. Specular surfaces do not store measurement points, rather the point continues along the path, reducing the pixel contribution by the specular reflectance. We converted the existing photon map kd-tree to hold the measurement points since we noticed severe performance limitations with the large amount of stored points. 

Adaptive photon mapping uses the adaptive Markov chain sampling to mutate the path and replica exchange to mix between uniform and Markov chain sampling to prevent becoming stuck any local peaks. During each successive photon pass, we first emit a photon from the square light in a randomly sampled direction, which is distributed according to $p(x)=\cos \theta/\pi$. This photon becomes the new good path if it hits a sample point. Otherwise we continue the pass by mutating the existing good path by the following:
$$du_i = sgn(2\xi_1 - 1)\xi_2^{(\frac{1}{d_i}+1)}$$
$$d_i = d_{i-1} + \gamma_i(a_i - a^*)$$
$$\gamma_i = \frac{1}{i}$$
$$a^* = 0.234$$

This mutation strategy is applied in four dimensions; the photon direction in spherical coordinates and the position along the square light. Additionally for this assignment, we store the spherical coordinates for multiple bounces to mutate. This photon then becomes the good path if it hits a measurement point. Otherwise we sample the existing good path again. The measurement point's flux and radius are adjusted every 10,000 iterations. We found that a lower number of photons per pass gave us a sharper image. Initially we set the measurement point radius to $0.25$. On each pass, we adjust the radius $ \hat{R}(x) $ and $\tau_N(x, \omega)$ according to the user-defined ratio $ \alpha $ set to 0.7. The only formula that differs from previous assignments is the flux correction premultiplying the BRDF $f_r(x,\omega,\omega_p)$ since we are now interested in the scene radiance:

$$ \tau_N(x, \omega) = \sum_{p=1}^{N(x)} f_r(x,\omega,\omega_p){\phi}'(x_p, \omega_p) $$

We normalize the radiance for each hit point by the probability of hitting a measurement point using a uniform photon.

$$ F = \frac{\tau_{N}(x, w)}{(\pi R(x)^2) N_{emitted}}*\frac{N_{hit}}{N_{total}} $$

Similar to Assignment 2, we adjusted the flux around the square edges. Initially, the scene corners were too bright since they sampled photons located within the radius. We added a normal check to ensure only the photons located on the same plane were accumulated. However, this resulted in very dark corners. We therefore decided to scale the contribution of photons that hit the boundary points whose radius extend beyond the diffuse squares. We calculated the scaling factor by utilizing the intersection points of the circle determined by the measurement point radius with each square's edges. The scaling factor is the ratio between the proportional area and the area assumed by the circle of radius $R(x)$. The scaling factor is applied to the newly accumulated flux $\tau_M$. While this approach is an approximation, we noticed an improvement in image quality above the previous two alternatives.

The results can be seen in figures \ref{fig:adaptive_100000}, \ref{fig:adaptive_1000000}, \ref{fig:adaptive_10000000} and \ref{fig:adaptiveppm_gray_100000000}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imgs/adaptiveppm_gray_100000}\\
    \caption{Adaptive photon mapping, .1 million photons}
    \label{fig:adaptive_100000}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imgs/adaptiveppm_gray_1000000}\\
    \caption{Adaptive photon mapping, 1 million photons}
    \label{fig:adaptive_1000000}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imgs/adaptiveppm_gray_10000000}\\
    \caption{Adaptive photon mapping, 10 million photons}
    \label{fig:adaptive_10000000}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{imgs/adaptiveppm_gray_100000000}\\
    \caption{Adaptive photon mapping, 100 million photons}
    \label{fig:adaptive_10000000}
\end{figure}
\pagebreak

We finally rendered a pretty scene!

\subsection*{Error analysis}
We compare each pixel value after the last sample ray for Monte Carlo path tracing to each measurement point in order to visualize how the errors decreased over time. We calculated the mean square error over the interval for different number of pixels, $Err = 1/N_p \sum_{i=1}^{N_p} (F_{i,a} - F_{i,p})^2$, where $F_{i,a}$ and $F_{i,p}$ is the pixel value for point $i$ for specified intervals of Adaptive Photon Mapping for 100 million photons, and Monte Carlo path tracing for ~2.6 billion samples. Figure \ref{fig:adaptive_msq} shows the mean square error for different number of samples.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{plots/adaptiveppm_gray_msq}\\
    \caption{Adaptive photon mapping, mean square error}
    \label{fig:adaptive_msq}
\end{figure}

Adaptive photon mapping converges quickly, but contains a larger mean squared error than the following Metropolis method. We tried a variety of debugging methods to identify the 0.02 discrepancy that met with little success. However, despite the small difference, we believe the image quality is comparible to Metropolis. 




